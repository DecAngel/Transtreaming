defaults:
  - stdetr_s
  - _self_

backbone:
  presnet:
    depth: 50
    variant: d
    freeze_at: 0
    return_idx: [1, 2, 3]
    num_stages: 4
    freeze_norm: True
    pretrained: True
  hybrid_encoder:
    in_channels: [512, 1024, 2048]
    feat_strides: [8, 16, 32]
    hidden_dim: 256
    use_encoder_idx: [2]
    num_encoder_layers: 1
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.
    enc_act: 'gelu'
    expansion: 1.0
    depth_mult: 1
    act: 'silu'
head:
  transformer:
    feat_channels: [256, 256, 256]
    feat_strides: [8, 16, 32]
    hidden_dim: 256
    num_levels: 3
    num_layers: 6
    num_queries: 300
    num_denoising: 100
    label_noise_ratio: 0.5
    box_noise_scale: 1.0 # 1.0 0.4
    eval_idx: -1
  criterion:
    weight_dict: { loss_vfl: 1, loss_bbox: 5, loss_giou: 2, }
    losses: [ 'vfl', 'boxes', ]
    alpha: 0.75
    gamma: 2.0
    matcher:
      _target_: src.models.layers.detr.detr_utils.HungarianMatcher
      weight_dict: { cost_class: 2, cost_bbox: 5, cost_giou: 2 }
      alpha: 0.25
      gamma: 2.0
      use_focal_loss: True
  postprocessor:
    _target_: src.models.layers.detr.rtdetr_postprocessor.RTDETRPostProcessor
    num_classes: 80
    use_focal_loss: True
    num_top_queries: 300
transform:
  _target_: src.models.transforms.torchvision_transform.TVTransform
  _recursive_: True
  train_ops:
    - _target_: torchvision.transforms.v2.RandomPhotometricDistort
      p: 0.5
    - _target_: torchvision.transforms.v2.RandomZoomOut
      fill: 0
      p: 0.5
    - _target_: src.models.transforms.torchvision_transform.RandomIoUCrop
      min_scale: 0.3
      max_scale: 1.0
      min_aspect_ratio: 1.2
      max_aspect_ratio: 2.0
      p: 0.8
    - _target_: torchvision.transforms.v2.RandomHorizontalFlip
    - _target_: torchvision.transforms.v2.Resize
      size: [600, 960]
    - _target_: src.models.transforms.torchvision_transform.SanitizeBoundingBoxes
      min_size: 1
optim:
  partial_optimizer:
    lr: 0.00004
