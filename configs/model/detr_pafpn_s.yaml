_target_: src.primitives.model.BaseModel
backbone:
  _target_: src.models.backbones.detr_backbone.DETRBackbone
  _recursive_: True
  presnet:
    _target_: src.models.layers.detr.presnet.PResNet
    depth: 18
    variant: d
    freeze_at: -1
    return_idx: [1, 2, 3]
    num_stages: 4
    freeze_norm: False
    pretrained: True
  hybrid_encoder:
    _target_: src.models.layers.detr.hybrid_encoder.HybridEncoder
    in_channels: [128, 256, 512]
    feat_strides: [ 8, 16, 32 ]
    # intra
    hidden_dim: 128
    use_encoder_idx: [ 2 ]
    num_encoder_layers: 1
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.
    enc_act: 'gelu'
    # cross
    expansion: 0.5
    depth_mult: 1
    act: 'silu'
neck:
  _target_: src.models.necks.identity_neck.IdentityNeck
head:
  _target_: src.models.heads.detr_head.DetrHead
  _recursive_: True
  transformer:
    _target_: src.models.layers.detr.rtdetrv2_decoder.RTDETRTransformerv2
    feat_channels: [ 256, 256, 256 ]
    feat_strides: [ 8, 16, 32 ]
    hidden_dim: 256
    num_levels: 3
    num_layers: 3
    num_queries: 300
    num_denoising: 100
    label_noise_ratio: 0.5
    box_noise_scale: 1.0 # 1.0 0.4
    eval_idx: -1
    # NEW
#    num_points: [ 4, 4, 4 ] # [3,3,3] [2,2,2]
#    cross_attn_method: default # default, discrete
#    query_select_method: default # default, agnostic
  criterion:
    _target_: src.models.layers.detr.rtdetrv2_criterion.RTDETRCriterionv2
    _recursive_: True
    weight_dict: {loss_vfl: 1, loss_bbox: 5, loss_giou: 2,}
    losses: ['vfl', 'boxes', ]
    alpha: 0.75
    gamma: 2.0
    matcher:
      _target_: src.models.layers.detr.detr_utils.HungarianMatcher
      weight_dict: {cost_class: 2, cost_bbox: 5, cost_giou: 2}
      alpha: 0.25
      gamma: 2.0
      use_focal_loss: True
  postprocessor:
    _target_: src.models.layers.detr.rtdetr_postprocessor.RTDETRPostProcessor
    use_focal_loss: True
    num_top_queries: 100
transform:
  _target_: src.models.transforms.kornia_transform.KorniaTransform
  train_aug:
    - _target_: kornia.augmentation.RandomHorizontalFlip
  train_size:
    - [496, 800]
    - [496, 816]
    - [512, 832]
    - [528, 848]
    - [528, 864]
    - [544, 880]
    - [560, 896]
    - [560, 912]
    - [576, 928]
    - [576, 944]
    - [592, 960]
    - [608, 976]
    - [608, 992]
    - [624, 1008]
    - [640, 1024]
    - [640, 1040]
    - [656, 1056]
    - [656, 1072]
    - [672, 1088]
    - [688, 1104]
    - [688, 1120]
  eval_size: [600, 960]
  original_size: True
metric:
  _target_: src.models.metrics.cocoeval_metric.COCOEvalMetric
  eval_coco: ${paths.data_dir}argoverse/Argoverse-HD/annotations/val.json
  test_coco: ${paths.data_dir}argoverse/Argoverse-HD/annotations/val.json
  future_time_constant: [1]
optim:
  _target_: src.models.optims.regex_optim.RegexOptim
  _recursive_: True
  partial_optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    lr: 0.001
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001
  partial_scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    _partial_: True
    max_lr: 0.001
    total_steps: 10000
#  partial_scheduler:
#    _target_: torch.optim.lr_scheduler.MultiStepLR
#    _partial_: True
#    milestones: [ 1000 ]
#    gamma: 0.1
  params:
    - params: '^(?=.*backbone)(?!.*norm).*$'
      lr: 0.0001
    - params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$'
      weight_decay: 0.

torch_compile: null
record_interval: 0
